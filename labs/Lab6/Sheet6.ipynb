{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aKnXMeBF_Xtv"
   },
   "source": [
    "# Important Information\n",
    "\n",
    "This file has two usages. \n",
    "1. This file can be displayed in Jupyter. You can read the task and insert your answers here. Start the notebook from an Anaconda prompt and change to the working directory containing the *.ipynb file.\n",
    "2. You can execute the code in Google Colab making use of Keras and Tensorflow. If you do not want to create a Google Account, you have to create a local environment for Keras and Tensorflow.\n",
    "\n",
    "For submission, convert your notebook with your solutions and all images to a pdf-file and upload this file into OLAT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z4a6N7WY_Xty"
   },
   "source": [
    "Setup for this exercise sheet. Download data and define Tensorflow version.\n",
    "Execute code only if you setup your enviroment correctly or if you are inside a colab enviroment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "K1NPLVMR_Xtz"
   },
   "outputs": [],
   "source": [
    "\n",
    "! git clone https://gitlab+deploy-token-26:XBza882znMmexaQSpjad@git.informatik.uni-kiel.de/las/nndl.git\n",
    "\n",
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "ufLTONnJ_Xt7"
   },
   "source": [
    "## Exercise 1 (Transfer learning, CNN model library):\n",
    "\n",
    "The following Jupyter notebook contains code to adapt a pre-trained model from the CNN model library (in this case MobileNetV2, pre-trained on ImageNet) to a different dataset (in this case the \"cats_vs_dogs\" dataset). Run the code, explain the individual steps and interpret the results.\n",
    "The code is based on https://www.tensorflow.org/tutorials/images/transfer_learning which may be consulted for reference.\n",
    "\n",
    "Then, use a different model, e.g. ‘ResNet101’ instead of ‘MobileNetV2’, and a different data set, e.g. ‘imagenette’ instead of ‘cats_vs_dogs’ and report on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0-MpFAKn_Xt8"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-790b92e68e4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdadelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdagrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNadam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Flatten\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adadelta, Adagrad, Nadam, RMSprop, schedules\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "### -----------\n",
    "# configuration\n",
    "### -----------\n",
    "\n",
    "img_size = 160\n",
    "batch_size = 32\n",
    "shuffle_buffer_size = 1000\n",
    "learning_rate = 0.0001\n",
    "num_initial_epochs = 10\n",
    "fine_tune_at_layer = 100 # layer number after which fine-tuning should be performed (layers until this layer number are frozen)\n",
    "num_fine_tuning_epochs = 10\n",
    "num_classes = 1 # cats_vs_dogs has 1 class (i.e., 2 classes), imagenette has 10 classes, caltech101 has 101 classes, caltech_birds 200 classes\n",
    "\n",
    "img_shape = (img_size, img_size, 3)\n",
    "total_epochs = num_initial_epochs + num_fine_tuning_epochs\n",
    "\n",
    "### -------\n",
    "# load data\n",
    "### -------\n",
    "\n",
    "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split = ['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info = True,\n",
    "    as_supervised = True)\n",
    "\n",
    "print(raw_train)\n",
    "print(raw_validation)\n",
    "print(raw_test)\n",
    "\n",
    "# show the first two images and labels from the training set\n",
    "get_label_name = metadata.features['label'].int2str\n",
    "\n",
    "for image, label in raw_train.take(2):\n",
    "  plt.figure()\n",
    "  plt.imshow(image)\n",
    "  plt.title(get_label_name(label))\n",
    "\n",
    "###------------- some statistics over training data ---------------------\n",
    "\n",
    "image_list = []\n",
    "label_list = []\n",
    "\n",
    "for images, labels in raw_train.take(-1):\n",
    "  image_list.append(images.numpy())\n",
    "  label_list.append(labels.numpy())\n",
    "\n",
    "print(\"Number of training images: %d\" % len(image_list))\n",
    "print(\"Number of training labels: %d\" % len(label_list))\n",
    "print(\"Shape of first training image: %s\" % str(image_list[0].shape))\n",
    "print(\"Shape of second training image: %s\" % str(image_list[1].shape))\n",
    "\n",
    "# calculate some statistics over training images (minimal / maximal pixel value, mean pixel dimensions)\n",
    "min_pixel_value_per_image = np.zeros(len(image_list))\n",
    "max_pixel_value_per_image = np.zeros(len(image_list))\n",
    "dim_per_image = np.zeros((len(image_list),3))\n",
    "\n",
    "for i in range(len(image_list)):\n",
    "  min_pixel_value_per_image[i] = np.min(image_list[i])\n",
    "  max_pixel_value_per_image[i] = np.max(image_list[i])\n",
    "  dim_per_image[i] = image_list[i].shape\n",
    "\n",
    "print(\"minimal pixel value in training data: %f\" % np.min(min_pixel_value_per_image) )\n",
    "print(\"maximal pixel value in training data: %f\" % np.max(max_pixel_value_per_image) )\n",
    "print(\"mean pixel dimension in training data: %s\" % np.mean(dim_per_image, axis=0))\n",
    "print(\"std. dev. of mean pixel dimension in training data: %s\" % np.std(dim_per_image, axis=0, ddof=1))\n",
    "\n",
    "# statistics over labels:\n",
    "labels_numpy = np.array([label_list])\n",
    "print(\"minimal label in training data: %d\" % np.min(labels_numpy))\n",
    "print(\"maximal label in training data: %d\" % np.max(labels_numpy))\n",
    "print(\"number of non-zero labels in training data: %d\" % np.count_nonzero(labels_numpy))\n",
    "\n",
    "\n",
    "###-----------\n",
    "# process data\n",
    "###-----------\n",
    "\n",
    "# format images for the task, using the tf.image module:\n",
    "# resize the images to a fixed input size (img_size x img_size), \n",
    "# and rescale the input channels to a range of [-1,1]\n",
    "# the resize method by default does not preserve aspect ratio; \n",
    "# this may result in resized images being distorted\n",
    "# alternatively, you may use the resize_with_pad method\n",
    "# or set the parameter preserve_aspect_ratio=True in the resize method.\n",
    "# see also https://www.tensorflow.org/api_docs/python/tf/image/resize#used-in-the-notebooks_1\n",
    "def format_example(image, label):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image = (image/127.5) - 1 # maximal pixel value: 255, so rescaling leads to a range of [-1, 1]\n",
    "  image = tf.image.resize(image, (img_size, img_size))\n",
    "  return image, label\n",
    "\n",
    "# apply formatting function to each item in the dataset using the map method\n",
    "train = raw_train.map(format_example)\n",
    "validation = raw_validation.map(format_example)\n",
    "test = raw_test.map(format_example)\n",
    "\n",
    "# shuffle and batch the data\n",
    "train_batches = train.shuffle(shuffle_buffer_size).batch(batch_size)\n",
    "validation_batches = validation.batch(batch_size)\n",
    "test_batches = test.batch(batch_size)\n",
    "\n",
    "# inspect a batch of data\n",
    "for image_batch, label_batch in train_batches.take(1): \n",
    "  pass\n",
    "\n",
    "print(\"shape of first training batch: %s\" % image_batch.shape)\n",
    "\n",
    "### ----------\n",
    "# create model\n",
    "### ----------\n",
    "\n",
    "# get base model from the pre-trained model MobileNetV2\n",
    "# this model contains the layers until the \"bottleneck\" (i.e. the layers before the fully connected layers)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=img_shape, \n",
    "                                               include_top=False, weights='imagenet')\n",
    "\n",
    "# let's see what this base model does to an input batch of size (batch_size, img_size, img_size, 3), e.g. (32, 160, 160, 3):\n",
    "feature_batch = base_model(image_batch)\n",
    "print(\"Shape of one feature batch: %s\" % str(feature_batch.shape) )\n",
    "\n",
    "\n",
    "# freeze the base_model (i.e., the convolutional feature extractor)\n",
    "base_model.trainable = False\n",
    "\n",
    "# print base model summary\n",
    "print(\"Base model:\")\n",
    "base_model.summary()\n",
    "\n",
    "# add a classification head via global average pooling, a fully connected layer and an output\n",
    "global_average_layer = GlobalAveragePooling2D()\n",
    "# just for information: shape of one feature batch after global average pooling \n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(\"Shape of one feature batch after global average pooling: %s\" % str(feature_batch_average.shape) )\n",
    "\n",
    "# use a fully connected layer to convert these features into a single prediction per image\n",
    "# remember that there are only 2 classes in the 'cats_vs_dogs' data set so a single output is enough\n",
    "# we do not need a sigmoid activation function because the prediction will be treated as logit \n",
    "# (i.e., raw number): Positive numbers predict class 1, negative numbers predict class 0.\n",
    "prediction_layer = Dense(num_classes) \n",
    "# just for information: shape of one feature batch after prediction layer \n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(\"Shape of one feature batch after prediction layer: %s\" % str(prediction_batch.shape) )\n",
    "\n",
    "# now put together the base model (i.e., feature extractor) and the two prediction layers \n",
    "# using a Sequential model\n",
    "model = Sequential([base_model, global_average_layer, prediction_layer])\n",
    "\n",
    "opt = RMSprop(learning_rate=learning_rate)\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "print(\"Final model (frozen base model with trainable classification head):\")\n",
    "model.summary()\n",
    "\n",
    "# evaluate initial model\n",
    "loss0_val, accuracy0_val = model.evaluate(validation_batches)\n",
    "print(\"initial loss on validation data: %f\" % loss0_val)\n",
    "print(\"initial accuracy on validation data: %f\" %accuracy0_val)\n",
    "\n",
    "loss0_test, accuracy0_test = model.evaluate(test_batches)\n",
    "print(\"initial loss on test data: %f\" % loss0_test)\n",
    "print(\"initial accuracy on test data: %f\" % accuracy0_test)\n",
    "\n",
    "\n",
    "### ---------\n",
    "# train model\n",
    "### ---------\n",
    "\n",
    "history = model.fit(train_batches, epochs=num_initial_epochs, validation_data=validation_batches)\n",
    "\n",
    "# plot training and validation loss and accuracy\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# evaluate initially trained model\n",
    "loss1_val, accuracy1_val = model.evaluate(validation_batches)\n",
    "print(\"loss on validation data after initial training: %f\" % loss1_val)\n",
    "print(\"accuracy on validation data after initial training: %f\" % accuracy1_val)\n",
    "\n",
    "loss1_test, accuracy1_test = model.evaluate(test_batches)\n",
    "print(\"loss on test data after initial training: %f\" % loss1_test)\n",
    "print(\"accuracy on test data after initial training: %f\" % accuracy1_test)\n",
    "\n",
    "\n",
    "### ---------\n",
    "# Fine-tuning\n",
    "### ---------\n",
    "\n",
    "# should only be done after training of the classification head where the base_model is frozen (not trainable)!!!\n",
    "# un-freeze the top layers of the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# print number of layers of the base model\n",
    "print(\"Number of layers in the base model: %d\" % len(base_model.layers) )\n",
    "\n",
    "# freeze all the layers before the 'fine_tune_at_layer' layer\n",
    "for layer in base_model.layers[:fine_tune_at_layer]:\n",
    "  layer.trainable = False\n",
    "\n",
    "# compile the model again, using a much lower learning rate\n",
    "opt = RMSprop(learning_rate=learning_rate/10.0)\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "print(\"Final model (partly frozen base model with trainable classification head):\")\n",
    "model.summary()\n",
    "print(\"Number of trainable layers: %d\" % len(model.trainable_variables))\n",
    "\n",
    "# fine-tune model\n",
    "history_fine_tuning = model.fit(train_batches, epochs = total_epochs,\n",
    "                                initial_epoch = history.epoch[-1], validation_data=validation_batches )\n",
    "\n",
    "# plot training and validation loss and accuracy\n",
    "acc += history_fine_tuning.history['accuracy']\n",
    "val_acc += history_fine_tuning.history['val_accuracy']\n",
    "\n",
    "loss += history_fine_tuning.history['loss']\n",
    "val_loss += history_fine_tuning.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.ylim([0.8, 1])\n",
    "plt.plot([num_initial_epochs-1,num_initial_epochs-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.plot([num_initial_epochs-1,num_initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "# evaluate fine-tuned  model\n",
    "loss2_val, accuracy2_val = model.evaluate(validation_batches)\n",
    "print(\"loss on validation data after fine-tuning: %f\" % loss2_val)\n",
    "print(\"accuracy on validation data after fine-tuning: %f\" % accuracy2_val)\n",
    "\n",
    "loss2_test, accuracy2_test = model.evaluate(test_batches)\n",
    "print(\"loss on test data after fine-tuning: %f\" % loss2_test)\n",
    "print(\"accuracy on test data after fine-tuning: %f\" % accuracy2_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xhNUG_V__XuB"
   },
   "source": [
    "### Answer\n",
    "\n",
    "Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m6L_OlQB_XuC"
   },
   "source": [
    "## Exercise 2 (Simple recurrent neural network for character sequences):\n",
    "\n",
    "The python script below, which is based on the script min-char-rnn.py\n",
    "written by Andrej Karpathy (see https://gist.github.com/karpathy/d4dee566867f8291f086),\n",
    "implements a simple recurrent neural network applied to predict the next character in a sequence\n",
    "of characters, based on the current character (see also the lecture slides).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "p7RoY9Lu_XuE"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "min-char-rnn.py: Written by Andrej Karpathy, minimally modified by CM\n",
    "Minimal character-level Vanilla RNN model. Written by Andrej Karpathy (@karpathy)\n",
    "from https://gist.github.com/karpathy/d4dee566867f8291f086\n",
    "adjusted for python 3 (CM, put brackets to print command)\n",
    "BSD License\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# data I/O\n",
    "data = open('nndl/Lab6/input_short.txt', 'r').read() # should be simple plain text file\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "# hyperparameters\n",
    "hidden_size = 100 # size of hidden layer of neurons\n",
    "seq_length = 25   # number of steps to unroll the RNN for, must be smaller than input text!\n",
    "learning_rate = 1e-1\n",
    "\n",
    "# model parameters\n",
    "Wxh = np.random.randn(hidden_size, vocab_size)*0.01 # input to hidden\n",
    "Whh = np.random.randn(hidden_size, hidden_size)*0.01 # hidden to hidden\n",
    "Why = np.random.randn(vocab_size, hidden_size)*0.01 # hidden to output\n",
    "bh = np.zeros((hidden_size, 1)) # hidden bias\n",
    "by = np.zeros((vocab_size, 1)) # output bias\n",
    "\n",
    "\n",
    "def lossFun(inputs, targets, hprev):\n",
    "  \"\"\"\n",
    "  inputs,targets are both list of integers.\n",
    "  hprev is Hx1 array of initial hidden state\n",
    "  returns the loss, gradients on model parameters, and last hidden state\n",
    "  \"\"\"\n",
    "  xs, hs, ys, ps = {}, {}, {}, {}\n",
    "  hs[-1] = np.copy(hprev)\n",
    "  loss = 0\n",
    "  # forward pass\n",
    "  for t in range(len(inputs)): # remark: xrange -> range\n",
    "    xs[t] = np.zeros((vocab_size,1)) # encode in 1-of-k representation\n",
    "    xs[t][inputs[t]] = 1\n",
    "    hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh) # hidden state\n",
    "    ys[t] = np.dot(Why, hs[t]) + by # unnormalized log probabilities for next chars\n",
    "    ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t])) # probabilities for next chars\n",
    "    loss += -np.log(ps[t][targets[t],0]) # softmax (cross-entropy loss) (negative log probability of the correct answer)\n",
    "    # remark CM: this is actually the log-likelihood loss; ps[t][targets[t],0] extracts the output probability ps[t] at the component of the target (targets[t],0); second index 0 because it's a column vector with 1 column  \n",
    "  # backward pass: compute gradients going backwards\n",
    "  dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "  dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
    "  dhnext = np.zeros_like(hs[0])\n",
    "  for t in reversed(range(len(inputs))): # remark: xrange -> range\n",
    "  # remark CM: going backwards the seq_length examples\n",
    "    dy = np.copy(ps[t])\n",
    "    dy[targets[t]] -= 1 # backprop into y. see http://cs231n.github.io/neural-networks-case-study/#grad if confused here\n",
    "    # remark CM: As explained on website, by computing the gradient, the score of the correct class is subtracted by 1 \n",
    "    dWhy += np.dot(dy, hs[t].T)\n",
    "    dby += dy\n",
    "    dh = np.dot(Why.T, dy) + dhnext # backprop into h\n",
    "    dhraw = (1 - hs[t] * hs[t]) * dh # backprop through tanh nonlinearity\n",
    "    dbh += dhraw\n",
    "    dWxh += np.dot(dhraw, xs[t].T)\n",
    "    dWhh += np.dot(dhraw, hs[t-1].T)\n",
    "    dhnext = np.dot(Whh.T, dhraw)\n",
    "  for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
    "    np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients\t\n",
    "  return loss, dWxh, dWhh, dWhy, dbh, dby, hs[len(inputs)-1]\n",
    "\n",
    "def sample(h, seed_ix, n):\n",
    "  \"\"\" \n",
    "  sample a sequence of integers from the model \n",
    "  h is memory state, seed_ix is seed letter for first time step\n",
    "  \"\"\"\n",
    "  x = np.zeros((vocab_size, 1))\n",
    "  x[seed_ix] = 1\n",
    "  ixes = []\n",
    "  for t in range(n): # remark: xrange -> range\n",
    "    h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
    "    y = np.dot(Why, h) + by\n",
    "    p = np.exp(y) / np.sum(np.exp(y))\n",
    "    ix = np.random.choice(range(vocab_size), p=p.ravel())\n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    x[ix] = 1\n",
    "    ixes.append(ix)\n",
    "  return ixes\n",
    "\n",
    "# levenshtein distance for comparison of text strings\n",
    "# from http://stackabuse.com/levenshtein-distance-and-text-similarity-in-python/\n",
    "def levenshtein(seq1, seq2):  \n",
    "    size_x = len(seq1) + 1\n",
    "    size_y = len(seq2) + 1\n",
    "    matrix = np.zeros ((size_x, size_y))\n",
    "    for x in range(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in range(size_y):\n",
    "        matrix [0, y] = y\n",
    "\n",
    "    for x in range(1, size_x):\n",
    "        for y in range(1, size_y):\n",
    "            if seq1[x-1] == seq2[y-1]:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1, y] + 1,\n",
    "                    matrix[x-1, y-1],\n",
    "                    matrix[x, y-1] + 1\n",
    "                )\n",
    "            else:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1,y] + 1,\n",
    "                    matrix[x-1,y-1] + 1,\n",
    "                    matrix[x,y-1] + 1\n",
    "                )\n",
    "    print (matrix)\n",
    "    return (matrix[size_x - 1, size_y - 1])\n",
    "\n",
    "# main program\n",
    "global_start_time = time.time()    \n",
    "n, p = 0, 0\n",
    "mWxh, mWhh, mWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "mbh, mby = np.zeros_like(bh), np.zeros_like(by) # memory variables for Adagrad\n",
    "smooth_loss = -np.log(1.0/vocab_size)*seq_length # loss at iteration 0\n",
    "#while True: # original code\n",
    "while n < 10000:\n",
    "  # prepare inputs (we're sweeping from left to right in steps seq_length long)\n",
    "  if p+seq_length+1 >= len(data) or n == 0: \n",
    "    hprev = np.zeros((hidden_size,1)) # reset RNN memory\n",
    "    p = 0 # go from start of data\n",
    "  inputs = [char_to_ix[ch] for ch in data[p:p+seq_length]]\n",
    "  targets = [char_to_ix[ch] for ch in data[p+1:p+seq_length+1]]\n",
    "\n",
    "  # sample from the model now and then\n",
    "  # remark CM: sampling because the RNN outputs PROBABILITIES for each character at each time step\n",
    "  #            the actual letter is sampled from these probabilities\n",
    "  if n % 100 == 0:\n",
    "    # beginning at the first letter of the current sequence, sample 200 characters\n",
    "    sample_ix = sample(hprev, inputs[0], 200) \n",
    "    txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
    "    print('----\\nsample 200 letters from current position:\\n%s \\n----' % (txt, ))\n",
    "\n",
    "    # alternatively, starting with the first letter of the text, sample 100 characters\n",
    "    sample_ix = sample(np.zeros_like(hprev), char_to_ix[data[0]], 100) \n",
    "    txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
    "    print('sample 100 letters from beginning of text:\\n%s \\n----' % (data[0] + txt) ) # data[0] added because first letter is input and not predicted\n",
    "    print()\n",
    "    \n",
    "  # forward seq_length characters through the net and fetch gradient\n",
    "  # remark CM: hprev keeps track of the hidden state vector at the end of the current batch\n",
    "  #            which is fed in to the forward propagation of the next batch; i.e. it allows \n",
    "  #            to correctly initialise the subsequent batch in the next forward iteration\n",
    "  #            so the hidden state vectors are correctly propagated from batch to batch\n",
    "  #            (however, backpropagation is performed only for the last seq_length steps)\n",
    "  loss, dWxh, dWhh, dWhy, dbh, dby, hprev = lossFun(inputs, targets, hprev)\n",
    "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "  if n % 100 == 0: print('iter %d, loss: %f' % (n, smooth_loss)) # print progress\n",
    "  \n",
    "  # perform parameter update with Adagrad\n",
    "  for param, dparam, mem in zip([Wxh, Whh, Why, bh, by], \n",
    "                                [dWxh, dWhh, dWhy, dbh, dby], \n",
    "                                [mWxh, mWhh, mWhy, mbh, mby]):\n",
    "    mem += dparam * dparam\n",
    "    param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update\n",
    "\n",
    "  p += seq_length # move data pointer\n",
    "  n += 1 # iteration counter \n",
    "  \n",
    "training_time = time.time() - global_start_time\n",
    "print('Training duration (s) : ', training_time)\n",
    "  \n",
    "# final test: starting with the first letter of the text, sample as many characters as there were in the training file\n",
    "# NOTE: this is like a test on the training data, to check how good the text was remembered\n",
    "\n",
    "print(\"\\nFinal test: Trying to reproduce training sequence; predicted text:\\n\")\n",
    "# alternatively, starting with the first letter of the text, sample as many characters as there are in the training text\n",
    "sample_ix = sample(np.zeros_like(hprev), char_to_ix[data[0]], len(data)) \n",
    "predicted = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
    "predicted = data[0] + predicted # must insert first character, since it is not predicted\n",
    "print(\"%s\\n\" % predicted)\n",
    "num_errors = levenshtein(predicted, data)\n",
    "print(\"\\n... there are %d errors\" % num_errors)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TRujOAv9_XuI"
   },
   "source": [
    "a) Depict a diagram of the recurrent neural network (including the number of neurons in each\n",
    "layer, the activation functions, the update equations and the dimensions of the matrices and\n",
    "vectors involved). Describe in detail how the network processes a sequence of characters in\n",
    "training (what is input, what is output, unfolding) and how the network generates a sequence\n",
    "of characters. Run the script (on the input file `input_short.txt`) and describe the\n",
    "output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-qG9ExQj_XuI"
   },
   "source": [
    "### Answer\n",
    "\n",
    "Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "noWfPdh-_XuJ"
   },
   "source": [
    "b) Run the script 10 times (you may modify the python script correspondingly) and report on\n",
    "your finding. Vary the configuration of the network and important parameters and assess\n",
    "the network performance based on 10 runs of each modified configuration for the input file\n",
    "`input_short.txt`. Report on your findings and conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "odoeNvco_XuK"
   },
   "source": [
    "### Answer\n",
    "\n",
    "Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eceZo2PW_XuK"
   },
   "source": [
    "## Exercise 3 (Long Short Term Memory LSTM, time series prediction):\n",
    "\n",
    "a)  Consider an LSTM network with a single hidden layer composed of two LSTM units, i.e.\n",
    "#hidden = 2, which receives three-dimensional inputs x = $(x_1, x_2, x_3)^T$, i.e. the number of\n",
    "input features is #features = 3.\n",
    "\n",
    "The synaptic weight matrices are given as follows:\n",
    "\n",
    "Input gate:\n",
    "\n",
    "$W_{xi} = \\begin{pmatrix} 2 & 0 & 3 \\\\ 4 & 1 & 0 \\end{pmatrix} $ weights from input to input gate (#hidden $\\times$ #features)\n",
    "\n",
    "$W_{hi} = \\begin{pmatrix} -3 & 0 \\\\ -5 & 1 \\end{pmatrix} $ weights from hidden units to input gate (#hidden $\\times$ #hidden)\n",
    "\n",
    "$b_{i} = \\begin{pmatrix}  0 \\\\ -2 \\end{pmatrix} $  bias of input gate (vector of dimension #hidden)\n",
    "\n",
    "Forget gate:\n",
    "\n",
    "$W_{xf} = \\begin{pmatrix} 1 & 0 & -1 \\\\ 2 & 1 & 2 \\end{pmatrix} $ weights from input to forget gate (#hidden $\\times$ #features)\n",
    "\n",
    "$W_{hf} = \\begin{pmatrix} -2 & 0 \\\\ 2 & 1 \\end{pmatrix} $ weights from hidden units to forget gate (#hidden $\\times$ #hidden)\n",
    "\n",
    "$b_{f} = \\begin{pmatrix}  1 \\\\ -1 \\end{pmatrix} $  bias of forget gate (vector of dimension #hidden)\n",
    "\n",
    "\n",
    "Cell (“gate gate”):\n",
    "\n",
    "$W_{xg} = \\begin{pmatrix} 1 & -1 & 0 \\\\ 0 & 2 & 1 \\end{pmatrix} $ weights from input to “gate” gate (#hidden $\\times$ #features)\n",
    "\n",
    "$W_{hg} = \\begin{pmatrix} 2 & 0 \\\\ -1 & 1 \\end{pmatrix} $ weights from hidden units to “gate” gate (#hidden $\\times$ #hidden)\n",
    "\n",
    "$b_{g} = \\begin{pmatrix}  -1 \\\\ 2 \\end{pmatrix} $  bias of “gate” gate (vector of dimension #hidden)\n",
    "\n",
    "Output gate:\n",
    "\n",
    "$W_{xo} = \\begin{pmatrix} -1 & 2 & -2 \\\\ 0 & 1 &  1 \\end{pmatrix} $ weights from input to output gate (#hidden $\\times$ #features)\n",
    "\n",
    "$W_{ho} = \\begin{pmatrix} 1 & 1 \\\\ 0 & 2 \\end{pmatrix} $ weights from hidden units to output gate (#hidden $\\times$ #hidden)\n",
    "\n",
    "$b_{o} = \\begin{pmatrix}  -1 \\\\ -1 \\end{pmatrix} $  bias of output gate (vector of dimension #hidden)\n",
    "\n",
    "Both the hidden layer activations and the cell activations shall be initialized with 0:\n",
    "$a_{o} = \\begin{pmatrix}  0 \\\\ 0 \\end{pmatrix}, c_{o} = \\begin{pmatrix}  0 \\\\ 0 \\end{pmatrix} $.\n",
    "\n",
    "Further, there are four output units, i.e. #output = 4. The synaptic weight matrix between\n",
    "the hidden units and the outputs is given by\n",
    "\n",
    "$W_{yh} = \\begin{pmatrix} 2 & -1 \\\\ 0 & 3 \\\\ 1 & -1\\\\ 4 & 0 \\end{pmatrix} $ weights from hidden unit activations to output (#output  $\\times$  #hidden)\n",
    "\n",
    "$b_{y} = \\begin{pmatrix} 2 \\\\ 0  \\\\ -1\\\\ 1 \\end{pmatrix} $ bias of outputs (vector of dimension #output)\n",
    "\n",
    "For the output units, a ReLU activation function is used.\n",
    "\n",
    "Calculate the outputs in a many-to-many scenario, i.e. an output is calculated for each input\n",
    "vector, at the time steps $t = 1$ and $t = 2$ for the input sequence\n",
    "$x_{1} = \\begin{pmatrix} 1 \\\\ 0  \\\\ -1  \\end{pmatrix} x_{2} = \\begin{pmatrix} 0 \\\\ 1  \\\\ 1 \\end{pmatrix} $\n",
    "\n",
    "Optional: Draw a diagram of the LSTM network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HZy1lYD4_XuL"
   },
   "source": [
    "Note: Instead of the sigmoid function $\\sigma(z) = \\frac{1}{1+e^{-z}}$ the so-called “hard-sigmoid” function\n",
    "$\\sigma_{hard}$ is being used at the input, forget and output gate, which is defined as follows:\n",
    "\n",
    "$\\sigma_{hard} = max\\{0, min\\{1,0.2 \\cdot x + 0.5\\}\\}$ i.e. \n",
    "\n",
    "$\\sigma_{hard} = \\begin{cases}\n",
    "      0 & \\text{for $x < -2.5$}\\\\\n",
    "      0.2 \\cdot + 0.5 & \\text{for $-2.5 \\leq x \\leq 2.5$}\\\\\n",
    "      1 & \\text{for $x  > 2.5$}\n",
    "    \\end{cases}  $   \n",
    "    \n",
    "![hard vs. sigmoid function](images/hardvssigmoid.PNG)\n",
    "\n",
    "The code below demonstrates how this network can be implemented in Keras. You may use the script to check your solution. However, please also document intermediate steps in your calculations. Also be aware that the script uses a standard sigmoid activation function and *not* a hard-sigmoid; therefore, the script may produce slightly different results than those of your calculations (the error can be up to 0.1 for the second input; for every input, the deviation adds up and therefore increases over time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "O93u6Wx1_XuM"
   },
   "outputs": [],
   "source": [
    "# adapted from https://machinelearningmastery.com/return-sequences-and-return-states-for-lstms-in-keras/\n",
    "# see also https://keras.io/getting-started/sequential-model-guide/\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import numpy as np\n",
    "\n",
    "input_dim = 3      # dimensionality of input space\n",
    "num_lstm_units = 2 # number of hidden units \n",
    "output_dim = 4     # dimensionality of output space\n",
    "num_time_steps = 2 # number of time steps in sequence presented to the network\n",
    "num_samples = 1    # number of samples e.g. in training (here not relevant, therefore set to 1)\n",
    "\n",
    "# define the model\n",
    "inputs1 = Input(shape=(num_time_steps, input_dim)) \n",
    "lstm1, state_h, state_c = LSTM(num_lstm_units, return_sequences = True, return_state = True)(inputs1)\n",
    "out = Dense(output_dim, activation=\"relu\")(lstm1)\n",
    "model = Model(inputs=inputs1, outputs=[out, state_h, state_c]) # use preediction and last states as output\n",
    "\n",
    "\n",
    "w = [] # LSTM weights in Keras\n",
    "# LSTM weights are in list format, see e.g. model.weights or model.get_weights()\n",
    "# w[0] are the weights between input and hidden layer\n",
    "# w[1] are the recurrent weights within the hidden layer\n",
    "# w[2] are the biases \n",
    "# all parameters are stored in the format [input, forget, cell, output], where input, forget,\n",
    "# cell and output refer to the values for ALL LSTM units\n",
    "# e.g. w[2]=np.array([1,2,0,0,-2,-1,-0.5,1.5]): b_i = [1,2], b_f = [0,0], b_c = [-2, -1], b_o = [-0.5, 1.5]\n",
    "#w.append(np.zeros((feature_dim, 4*num_lstm_units))) # weights between input and hidden layer\n",
    "#w.append(np.zeros((num_lstm_units, 4 * num_lstm_units))) # recurrent weights within hidden layer\n",
    "#w.append(np.random.random_sample((4 * num_lstm_units))) # bias values (factor 4 for input, forget, cell and output)\n",
    "\n",
    "## specific example (2 LSTM units, 3 features)\n",
    "\n",
    "# weights from input to the gates \n",
    "w.append(np.array([[2,4,1,2,1,0,-1,0],[0,1,0,1,-1,2,2,1], [3,0,-1,2,0,1,-2,1]]))\n",
    "# recurrent weights\n",
    "w.append(np.array([[-3,-5,-2,2,2,-1,1,0],[0,1,0,1,0,1,1,2]]))\n",
    "# hidden biases\n",
    "w.append(np.array([0, -2, 1, -1, -1, 2, -1, -1]))\n",
    "# weights from hidden activations to output\n",
    "w.append(np.array([[2, 0, 1, 4],[-1, 3, -1, 0]]))\n",
    "# output biases\n",
    "w.append(np.array([2, 0, -1, 1]))\n",
    "model.set_weights(np.array(w))\n",
    "print(\"model weight summary: %s\" % model.weights)\n",
    "print(\"\\n\")\n",
    "print(\"model weights: %s\" % model.get_weights())\n",
    "print(\"\\n\")\n",
    "\n",
    "#x = np.random.random_sample((num_samples, num_time_steps, feature_dim))\n",
    "#x = np.zeros((num_samples, num_time_steps, feature_dim))\n",
    "x = np.array([[[1, 0, -1], [0, 1, 1],  [-1, 1, 1], [1, 0, 0]]]) # shape (1, 4, 3) \n",
    "x = x[:,:num_time_steps,:]\n",
    "print(\"input: %s\" % x)\n",
    "print(\"output: %s\" % model.predict(x))\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F0SDBzZn_XuS"
   },
   "source": [
    "b) The code below (copied from https://machinelearningmastery.com/stateful-stateless-lstm-time-series-forecastingpython/) implements a simple LSTM network to predict shampoo sales over a period of three years.\n",
    "Describe the LSTM network, the way how the network processes the time sequence to predict future shampoo sales (how many inputs of which dimension, how many outputs of what dimension?), and how training is performed (how many samples,\n",
    "what is the length of the sequence considered in truncated backpropagation through time?).\n",
    "Vary important parameters (repeating over several training runs) and comment on your findings.\n",
    "Note that to modify other parameters, certain conditions must hold, e.g. the batch size must be a factor of the number of training samples; but then, other architectural changes of the LSTM network have to be applied. This is beyond this small introductory exercise..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "lhP5FlyI_XuS"
   },
   "outputs": [],
   "source": [
    "# from https://machinelearningmastery.com/stateful-stateless-lstm-time-series-forecasting-python/\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "\n",
    "epochs = 3000\n",
    "num_lstm_units = 4\n",
    "batch_size = 1\n",
    "\n",
    "# load dataset\n",
    "def parser(x):\n",
    "\treturn datetime.strptime(x, '%y.%m.17')\n",
    "\n",
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "\tdf = DataFrame(data)\n",
    "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
    "\tcolumns.append(df)\n",
    "\tdf = concat(columns, axis=1)\n",
    "\tdf.fillna(0, inplace=True)\n",
    "\treturn df\n",
    " \n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    " \n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    " \n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    " \n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = numpy.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    " \n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "\tX, y = train[:, 0:-1], train[:, -1]\n",
    "\tX = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=False))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\tmodel.fit(X, y, epochs=nb_epoch, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "\treturn model\n",
    " \n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, 1, len(X))\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    " \n",
    "series = read_csv('nndl/Lab6/shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "# summarize first few rows\n",
    "print(series.head())\n",
    "# line plot\n",
    "series.plot()\n",
    "pyplot.show()\n",
    "\n",
    "# transform data to be stationary\n",
    "raw_values = series.values\n",
    "diff_values = difference(raw_values, 1)\n",
    " \n",
    "# transform data to be supervised learning\n",
    "supervised = timeseries_to_supervised(diff_values, 1)\n",
    "supervised_values = supervised.values\n",
    "\n",
    "# split data into train and test-sets\n",
    "train, test = supervised_values[0:-12], supervised_values[-12:]\n",
    " \n",
    "# transform the scale of the data\n",
    "scaler, train_scaled, test_scaled = scale(train, test)\n",
    " \n",
    "# fit the model\n",
    "lstm_model = fit_lstm(train_scaled, batch_size, epochs, num_lstm_units)\n",
    "# forecast the entire training dataset to build up state for forecasting\n",
    "train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
    "lstm_model.predict(train_reshaped, batch_size)\n",
    " \n",
    "# walk-forward validation on the test data\n",
    "predictions = list()\n",
    "for i in range(len(test_scaled)):\n",
    "\t# make one-step forecast\n",
    "\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\tyhat = forecast_lstm(lstm_model, batch_size, X)\n",
    "\t# invert scaling\n",
    "\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t# invert differencing\n",
    "\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t# store forecast\n",
    "\tpredictions.append(yhat)\n",
    "\texpected = raw_values[len(train) + i + 1]\n",
    "\tprint('Month=%d, Predicted=%f, Expected=%f' % (i+1, yhat, expected))\n",
    " \n",
    "# report performance\n",
    "rmse = sqrt(mean_squared_error(raw_values[-12:], predictions))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "# line plot of observed vs predicted\n",
    "pyplot.plot(raw_values[-12:])\n",
    "pyplot.plot(predictions)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jgw6NmRE_XuW"
   },
   "source": [
    "### Answer\n",
    "\n",
    "Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s2wPc6AI_XuW"
   },
   "source": [
    "# Exercise 4 (Autoencoder):\n",
    "\n",
    "a) (Standard autoencoder) The jupyter notebook provides code to train a standard autoencoder for encoding representations of the MNIST handwritten digits data. Run the code using different sizes of the encoded representations and different optimizers and discuss your results. In addition, add a sparsity constraint (L1 regularization) to the activities of the hidden neurons: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rowh1a2M_XuX"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dense' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bd429f66d897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mencoding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Dense' is not defined"
     ]
    }
   ],
   "source": [
    "encoded = Dense( encoding_dim, activation = 'relu', activity_regularizer=regularizers.l1(1e-5))(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fixqEgCY_Xuc"
   },
   "source": [
    "Again run the code and discuss your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5tAF2lCIJ_6_"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import Model # do NOT use tensorflow.keras.Model\n",
    "from keras.layers import Input, Dense # do NOT use tensorflow.keras.layers\n",
    "from keras import regularizers\n",
    "import tensorflow.keras.datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### -----------\n",
    "# configuration\n",
    "### -----------\n",
    "\n",
    "# this is the size of our encoded representation\n",
    "encoding_dim = 32 # e.g. for 32 floats: compression of factor 24.5, assuming the input is 784 floats  \n",
    "\n",
    "num_epochs = 50\n",
    "batch_size = 256\n",
    "opt = 'adadelta' # 'adadelta', 'adam' etc.; note: thoses are KERAS optimizers, not tensorflow optimizers (do not use them here)\n",
    "\n",
    "###--------\n",
    "# load data (autoencoders are trained in an unsupervised way, so we don't load targets)\n",
    "###--------\n",
    "\n",
    "(training_input, _), (test_input, _)  = tfds.mnist.load_data()\n",
    "\n",
    "print(\"min. training data: %f\" % np.min(training_input))\n",
    "print(\"max. training data: %f\" % np.max(training_input))\n",
    "print(\"min. test data: %f\" % np.min(test_input))\n",
    "print(\"max. test data: %f\" % np.max(test_input))\n",
    "\n",
    "training_input = training_input.astype('float32')\n",
    "test_input = test_input.astype('float32')\n",
    "\n",
    "# flatten images (size 28 x 28) to vectors of size 784\n",
    "training_input = training_input.reshape(training_input.shape[0], np.prod(training_input.shape[1:]))\n",
    "test_input = test_input.reshape(test_input.shape[0], np.prod(test_input.shape[1:]))\n",
    "\n",
    "print(\"training input shape: %s\"  % str(training_input.shape) )\n",
    "print(\"test input shape: %s \"  % str(test_input.shape) )\n",
    "# range of input values: 0 ... 255\n",
    "\n",
    "###-----------\n",
    "# process data\n",
    "###-----------\n",
    "\n",
    "# Note: shuffling is performed in fit method\n",
    "\n",
    "# scaling inputs from range 0 ... 255 to range [0,1] if desired\n",
    "scale_inputs = True # scale inputs to range [0,1]\n",
    "if scale_inputs:\n",
    "  training_input = training_input / 255\n",
    "  test_input = test_input / 255\n",
    "\n",
    "print(\"min. training data: %f\" % np.min(training_input))\n",
    "print(\"max. training data: %f\" % np.max(training_input))\n",
    "print(\"min. test data: %f\" % np.min(test_input))\n",
    "print(\"max. test data: %f\" % np.max(test_input))\n",
    "\n",
    "\n",
    "###-----------\n",
    "# define model\n",
    "###-----------\n",
    "\n",
    "# define input layer with 784 units\n",
    "if training_input.shape[1] == test_input.shape[1]:\n",
    "  num_inputs = training_input.shape[1]\n",
    "else:\n",
    "  print(\"number of inputs different in training and test?\")\n",
    "input = Input(shape=(num_inputs,)) # (num_inputs,) renders number of inputs a TUPLE, (num_inputs) is an INT\n",
    "\n",
    "# encoded is the encoded representation of the input\n",
    "encoded = Dense( encoding_dim, activation = 'relu')(input)\n",
    "\n",
    "# decoded is the lossy reconstruction of the input\n",
    "decoded = Dense( num_inputs, activation = 'sigmoid') (encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input, decoded)\n",
    "\n",
    "# create a separate encoder model (to later encode images): this model maps an input to its encoded representation\n",
    "encoder = Model(input, encoded)\n",
    "\n",
    "# create a separate decoder model (to later decode representations): this model maps a representation to a lossy reconstruction\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model( encoded_input, decoder_layer(encoded_input) )\n",
    "\n",
    "# model summaries\n",
    "print(\"Autoencoder:\")\n",
    "autoencoder.summary()\n",
    "print(autoencoder.get_config())\n",
    "\n",
    "print(\"Encoder:\")\n",
    "encoder.summary()\n",
    "\n",
    "print(\"Decoder:\")\n",
    "decoder.summary()\n",
    "\n",
    "autoencoder.compile(optimizer=opt, loss='binary_crossentropy') # do NOT use tensorflow optimizers\n",
    "\n",
    "###----------\n",
    "# train model\n",
    "###----------\n",
    "\n",
    "history = autoencoder.fit(training_input, training_input, epochs=num_epochs, batch_size=batch_size, \n",
    "                          shuffle = True, validation_data=(test_input, test_input) )\n",
    "\n",
    "# plot training loss  \n",
    "plt.plot(history.history['loss'], color = 'blue', label = 'training loss')\n",
    "plt.xlabel('Epoch number')\n",
    "#plt.ylim(0, 1)\n",
    "plt.title('training loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "###--------- \n",
    "# test model\n",
    "###---------\n",
    "\n",
    "encoded_images = encoder.predict(test_input)\n",
    "print(\"Mean value of encoded images: %f\" % encoded_images.mean())\n",
    "decoded_images = decoder.predict(encoded_images)\n",
    "\n",
    "# plot example images\n",
    "num_examples = 10 \n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(num_examples):\n",
    "  # display original\n",
    "  ax = plt.subplot(2, num_examples, i + 1)\n",
    "  plt.imshow(test_input[i].reshape(28, 28))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "\n",
    "  # display reconstruction\n",
    "  ax = plt.subplot(2, num_examples, i + 1 + num_examples)\n",
    "  plt.imshow(decoded_images[i].reshape(28, 28))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N3_4kfuM_Xug"
   },
   "source": [
    "### Answer\n",
    "\n",
    "Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "wl_FY5so_Xuh"
   },
   "source": [
    "b) (Convolutional autoencoder) The next jupyter notebook provides code to train a convolutional autoencoder for encoding representations of the MNIST handwritten digits data. Run the code and interpret your results including a comparison to the autoencoder from part a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "F7AjAbP__Xuh"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import Model # do NOT use tensorflow.keras.Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D # do NOT use tensorflow.keras.layers\n",
    "import tensorflow.keras.datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### -----------\n",
    "# configuration\n",
    "### -----------\n",
    "\n",
    "num_epochs = 50\n",
    "batch_size = 256\n",
    "opt = 'adam' # 'adadelta', 'adam' etc.; note: thoses are KERAS optimizers, not tensorflow optimizers (do not use them here)\n",
    "\n",
    "num_feature_maps_high = 32\n",
    "num_feature_maps_low = 16\n",
    "kernel_size = (3, 3)\n",
    "pool_size = (2, 2)\n",
    "padding = 'same'\n",
    "activation = 'relu'\n",
    "final_activation = 'sigmoid'\n",
    "\n",
    "\n",
    "###--------\n",
    "# load data (autoencoders are trained in an unsupervised way, so we don't load targets)\n",
    "###--------\n",
    "\n",
    "(training_input, _), (test_input, _)  = tfds.mnist.load_data()\n",
    "\n",
    "print(\"min. training data: %f\" % np.min(training_input))\n",
    "print(\"max. training data: %f\" % np.max(training_input))\n",
    "print(\"min. test data: %f\" % np.min(test_input))\n",
    "print(\"max. test data: %f\" % np.max(test_input))\n",
    "\n",
    "training_input = training_input.astype('float32')\n",
    "test_input = test_input.astype('float32')\n",
    "\n",
    "# flatten images (size 28 x 28) to vectors of size 784\n",
    "training_input = training_input.reshape(training_input.shape[0], 28, 28, 1) # must be adapted if using 'channels_first' image data format\n",
    "test_input = test_input.reshape(test_input.shape[0], 28, 28, 1) # must be adapted if using 'channels_first' image data format\n",
    "\n",
    "print(\"training input shape: %s\"  % str(training_input.shape) )\n",
    "print(\"test input shape: %s \"  % str(test_input.shape) )\n",
    "# range of input values: 0 ... 255\n",
    "\n",
    "###-----------\n",
    "# process data\n",
    "###-----------\n",
    "\n",
    "# Note: shuffling is performed in fit method\n",
    "\n",
    "# scaling inputs from range 0 ... 255 to range [0,1] if desired\n",
    "scale_inputs = True # scale inputs to range [0,1]\n",
    "if scale_inputs:\n",
    "  training_input = training_input / 255.\n",
    "  test_input = test_input / 255.\n",
    "\n",
    "print(\"min. training data: %f\" % np.min(training_input))\n",
    "print(\"max. training data: %f\" % np.max(training_input))\n",
    "print(\"min. test data: %f\" % np.min(test_input))\n",
    "print(\"max. test data: %f\" % np.max(test_input))\n",
    "\n",
    "\n",
    "###-----------\n",
    "# define model\n",
    "###-----------\n",
    "\n",
    "# define input layer for 28 x 28 gray scale images:\n",
    "img_shape = (28, 28, 1) # must be adapted if using 'channels_first' image data format\n",
    "input = Input(shape=img_shape) \n",
    "\n",
    "# encoder consisting of convolutional and pooling layers\n",
    "layer = Conv2D(num_feature_maps_high, kernel_size, activation=activation, padding=padding)(input)\n",
    "layer = MaxPooling2D(pool_size, padding=padding)(layer)\n",
    "layer = Conv2D(num_feature_maps_low, kernel_size, activation=activation, padding=padding)(layer)\n",
    "layer = MaxPooling2D(pool_size, padding=padding)(layer)\n",
    "layer = Conv2D(num_feature_maps_low, kernel_size, activation=activation, padding=padding)(layer)\n",
    "encoded = MaxPooling2D(pool_size, padding=padding)(layer)\n",
    "# at this point the representation is (4, 4, 8), i.e., 128-dimensional\n",
    "\n",
    "# decoder consisting of convolutional and upsampling layers\n",
    "layer = Conv2D(num_feature_maps_low, kernel_size, activation=activation, padding=padding)(encoded)\n",
    "layer = UpSampling2D(pool_size)(layer)\n",
    "layer = Conv2D(num_feature_maps_low, kernel_size, activation=activation, padding=padding)(layer)\n",
    "layer = UpSampling2D(pool_size)(layer)\n",
    "layer = Conv2D(num_feature_maps_high, kernel_size, activation=activation)(layer)\n",
    "layer = UpSampling2D(pool_size)(layer)\n",
    "decoded = Conv2D(1, kernel_size, activation=final_activation, padding=padding)(layer)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input, decoded)\n",
    "\n",
    "# create a separate encoder model (to later encode images): this model maps an input to its encoded representation\n",
    "encoder = Model(input, encoded)\n",
    "\n",
    "# model summaries\n",
    "print(\"Autoencoder:\")\n",
    "autoencoder.summary()\n",
    "print(autoencoder.get_config())\n",
    "\n",
    "print(\"Encoder:\")\n",
    "encoder.summary()\n",
    "\n",
    "autoencoder.compile(optimizer=opt, loss='binary_crossentropy') # do NOT use tensorflow optimizers\n",
    "\n",
    "###----------\n",
    "# train model\n",
    "###----------\n",
    "\n",
    "history = autoencoder.fit(training_input, training_input, epochs=num_epochs, batch_size=batch_size, \n",
    "                          shuffle = True, validation_data=(test_input, test_input))\n",
    "\n",
    "# plot training loss  \n",
    "plt.plot(history.history['loss'], color = 'blue', label = 'training loss')\n",
    "plt.xlabel('Epoch number')\n",
    "#plt.ylim(0, 1)\n",
    "plt.title('training loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "###--------- \n",
    "# test model\n",
    "###---------\n",
    "\n",
    "decoded_input = autoencoder.predict(test_input)\n",
    "\n",
    "# for plotting the internal representations\n",
    "encoded_input = encoder.predict(test_input)\n",
    "\n",
    "# plot example images\n",
    "num_examples = 10 \n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(num_examples):\n",
    "  # display original\n",
    "  ax = plt.subplot(2, num_examples, i + 1)\n",
    "  plt.imshow(test_input[i].reshape(28, 28))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "\n",
    "  # display reconstruction\n",
    "  ax = plt.subplot(2, num_examples, i + 1 + num_examples)\n",
    "  plt.imshow(decoded_input[i].reshape(28, 28))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, num_feature_maps_low))\n",
    "for i in range(num_examples):\n",
    "  # display representation\n",
    "  ax = plt.subplot(1, num_examples, i + 1)\n",
    "  plt.imshow(encoded_input[i].reshape(4, 4*num_feature_maps_low).T)\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t-GyCuDP_Xuk"
   },
   "source": [
    "### Answer\n",
    "\n",
    "Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h-e7Qqv8_Xul"
   },
   "source": [
    "c) (Denoising autoencoder) Apply the convolutional autoencoder from part b) to noisy input digits. To this end, synthetic Gaussian noise is added pixel-wise to the input images (where the resulting noisy pixel values arethen clipped to values in the interval [0,1]). This is achieved by the following code, which must be executed after the \"process data\" step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "AUvBqCDq_Xum"
   },
   "outputs": [],
   "source": [
    "###----------------------\n",
    "# add noise to input data\n",
    "###----------------------\n",
    "\n",
    "noise_factor = 0.5\n",
    "\n",
    "training_input_noisy = training_input + noise_factor * np.random.normal(loc=0.0, scale=1.0, size = training_input.shape)\n",
    "test_input_noisy = test_input + noise_factor * np.random.normal(loc=0.0, scale=1.0, size = test_input.shape)\n",
    "\n",
    "training_input_noisy = np.clip(training_input_noisy, 0., 1.)\n",
    "test_input_noisy = np.clip(test_input_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wHARtM7S_Xuq"
   },
   "source": [
    "In this case, training has to be performed using the noisy images as input and the original images as targets. In addition, the noisy images are used to calculate internal representations (and of course, the noisy input images have to be plotted):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "U0JQv-4h_Xuq"
   },
   "outputs": [],
   "source": [
    "history = autoencoder.fit(training_input_noisy, training_input, epochs=num_epochs, batch_size=batch_size, \n",
    "                          shuffle = True, validation_data=(test_input_noisy, test_input))\n",
    "\n",
    "decoded_input = autoencoder.predict(test_input_noisy)\n",
    "\n",
    "encoded_input = encoder.predict(test_input_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iwPD0khv_Xut"
   },
   "source": [
    "Modify the code accordingly, perform some experiments and report on your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pVcH5n-z_Xuv"
   },
   "source": [
    "### Answer\n",
    "\n",
    "Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vz9VGo4R_Xuv"
   },
   "source": [
    "d) (Variational autoencoder) The subsequent Jupyter notebook contains code to train a (convolutional) variational autoencoder on the MNIST data. Run the code and interpret the figures, thereby explaining briefly how a variational autoencoder works.\n",
    "\n",
    "(example based on https://www.kaggle.com/rvislaywade/visualizing-mnist-using-a-variational-autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "syMGz8C7_Xuw"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import Model # do NOT use tensorflow.keras.Model\n",
    "from keras.layers import Input, Conv2D, Dense, Flatten, Lambda, Reshape, Conv2DTranspose, Layer # do NOT use tensorflow.keras.layers\n",
    "from keras.metrics import binary_crossentropy\n",
    "import tensorflow.keras.datasets as tfds\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "### -----------\n",
    "# configuration\n",
    "### -----------\n",
    "\n",
    "# this is the size of our encoded representation\n",
    "img_shape = (28, 28, 1) # for MNIST\n",
    "\n",
    "num_epochs = 7\n",
    "batch_size = 16\n",
    "latent_dim = 2 # number of latent dimension parameters\n",
    "opt = 'rmsprop' # 'adadelta', 'adam' etc.; note: thoses are KERAS optimizers, not tensorflow optimizers (do not use them here)\n",
    "\n",
    "num_feature_maps_high = 64\n",
    "num_feature_maps_low = 32\n",
    "kernel_size = (3, 3)\n",
    "pool_size = (2, 2)\n",
    "padding = 'same'\n",
    "activation = 'relu'\n",
    "final_activation = 'sigmoid'\n",
    "\n",
    "###--------\n",
    "# load data (autoencoders are trained in an unsupervised way, but we need the labels for later visualization)\n",
    "###--------\n",
    "\n",
    "(training_input, training_target), (test_input, test_target)  = tfds.mnist.load_data()\n",
    "\n",
    "print(\"min. training data: %f\" % np.min(training_input))\n",
    "print(\"max. training data: %f\" % np.max(training_input))\n",
    "print(\"min. test data: %f\" % np.min(test_input))\n",
    "print(\"max. test data: %f\" % np.max(test_input))\n",
    "\n",
    "training_input = training_input.astype('float32')\n",
    "test_input = test_input.astype('float32')\n",
    "\n",
    "training_input = training_input.reshape(-1, 28, 28, 1) # must be adapted if using 'channels_first' image data format\n",
    "test_input = test_input.reshape(-1, 28, 28, 1) # must be adapted if using 'channels_first' image data format\n",
    "\n",
    "print(\"training input shape: %s\"  % str(training_input.shape) )\n",
    "print(\"test input shape: %s \"  % str(test_input.shape) )\n",
    "# range of input values: 0 ... 255\n",
    "\n",
    "###-----------\n",
    "# process data\n",
    "###-----------\n",
    "\n",
    "# Note: shuffling is performed in fit method\n",
    "\n",
    "# scaling inputs from range 0 ... 255 to range [0,1] if desired\n",
    "scale_inputs = True # scale inputs to range [0,1]\n",
    "if scale_inputs:\n",
    "  training_input = training_input / 255.\n",
    "  test_input = test_input / 255.\n",
    "\n",
    "print(\"min. training data: %f\" % np.min(training_input))\n",
    "print(\"max. training data: %f\" % np.max(training_input))\n",
    "print(\"min. test data: %f\" % np.min(test_input))\n",
    "print(\"max. test data: %f\" % np.max(test_input))\n",
    "\n",
    "###-----------\n",
    "# define model\n",
    "###-----------\n",
    "\n",
    "# Encoder architecture: Input -> Conv2D*4 -> Flatten -> Dense\n",
    "input_img = Input(shape=img_shape)\n",
    "\n",
    "x = Conv2D(num_feature_maps_low, kernel_size, padding=padding, activation=activation)(input_img)\n",
    "# next convolution downsamples the image\n",
    "x = Conv2D(num_feature_maps_high, kernel_size, padding=padding, activation=activation, strides=pool_size)(x)\n",
    "x = Conv2D(num_feature_maps_high, kernel_size, padding=padding, activation=activation)(x)\n",
    "x = Conv2D(num_feature_maps_high, kernel_size, padding=padding, activation=activation)(x)\n",
    "# need to know the shape of the network here for the decoder\n",
    "shape_before_flattening = K.int_shape(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(num_feature_maps_low, activation=activation)(x)\n",
    "\n",
    "# Two outputs, latent mean and (log)variance\n",
    "z_mu = Dense(latent_dim)(x)\n",
    "z_log_sigma = Dense(latent_dim)(x)\n",
    "\n",
    "\n",
    "# encoder model statement\n",
    "encoder = Model(input_img, z_mu)\n",
    "print(\"Encoder:\")\n",
    "encoder.summary()\n",
    "\n",
    "\n",
    "# sampling function\n",
    "def sampling(args):\n",
    "    z_mu, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mu)[0], latent_dim),\n",
    "                              mean=0., stddev=1.)\n",
    "    return z_mu + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "# sample vector from the latent distribution\n",
    "z = Lambda(sampling)([z_mu, z_log_sigma])\n",
    "\n",
    "# decoder takes the latent distribution sample as input\n",
    "decoder_input = Input(K.int_shape(z)[1:])\n",
    "\n",
    "# Expand to 784 total pixels\n",
    "x = Dense(np.prod(shape_before_flattening[1:]), activation=activation)(decoder_input)\n",
    "\n",
    "# reshape\n",
    "x = Reshape(shape_before_flattening[1:])(x)\n",
    "\n",
    "# use transpose convolution to reverse the conv layers from the encoder\n",
    "x = Conv2DTranspose(num_feature_maps_low, kernel_size, padding=padding, activation=activation, strides=pool_size)(x)\n",
    "# followed by a standard convolution\n",
    "x = Conv2D(1, kernel_size, padding=padding, activation=final_activation)(x)\n",
    "\n",
    "# decoder model statement\n",
    "decoder = Model(decoder_input, x)\n",
    "print(\"Decoder:\")\n",
    "decoder.summary()\n",
    "\n",
    "# apply the decoder to the sample from the latent distribution\n",
    "z_decoded = decoder(z)\n",
    "\n",
    "\n",
    "# define loss\n",
    "\n",
    "# construct a custom layer just to enable to calculate a custom loss\n",
    "class CustomVariationalLayer(Layer):\n",
    "\n",
    "    def vae_loss(self, x, z_decoded):\n",
    "        weighting_factor = 5e-4\n",
    "        x = K.flatten(x)\n",
    "        z_decoded = K.flatten(z_decoded)\n",
    "        # Reconstruction loss\n",
    "        xent_loss = binary_crossentropy(x, z_decoded)\n",
    "        # KL divergence (see Kingma and Welling, \"Auto-Encoding Variational Bayes\", Appendix F.1)\n",
    "        kl_loss = -weighting_factor * K.mean(1 + z_log_sigma - K.square(z_mu) - K.exp(z_log_sigma), axis=-1)\n",
    "        return K.mean(xent_loss + kl_loss)\n",
    "\n",
    "    # adds the custom loss to the class\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        z_decoded = inputs[1]\n",
    "        loss = self.vae_loss(x, z_decoded)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        return x\n",
    "\n",
    "# apply the custom loss to the input images and the decoded latent distribution sample\n",
    "y = CustomVariationalLayer()([input_img, z_decoded])\n",
    "\n",
    "# compile and plot model\n",
    "vae = Model(input_img, y)\n",
    "vae.compile(optimizer=opt, loss=None)\n",
    "print(\"Variational autoencoder:\")\n",
    "vae.summary()\n",
    "\n",
    "\n",
    "###----------\n",
    "# train model\n",
    "###----------\n",
    "\n",
    "history = vae.fit(x=training_input, y=None, shuffle=True, epochs=num_epochs, batch_size=batch_size,\n",
    "                  validation_data=(test_input, None))\n",
    "\n",
    "# plot training and validation loss  \n",
    "plt.plot(history.history['loss'], color = 'blue', label = 'training loss')\n",
    "plt.plot(history.history['val_loss'], color = 'red', label = 'validation loss')\n",
    "plt.xlabel('Epoch number')\n",
    "#plt.ylim(0, 1)\n",
    "plt.title('training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "###------------------------------------------------------------------------\n",
    "# Encode test images, i.e., transform them to latent space with the encoder\n",
    "###------------------------------------------------------------------------\n",
    "\n",
    "# Transform validation (i.e, test) data into the latent space\n",
    "test_input_encoded = encoder.predict(test_input, batch_size=batch_size)\n",
    "\n",
    "\n",
    "###----------------------------------------------------------------------\n",
    "# Example: Interpolation between latent representation of two test digits\n",
    "###----------------------------------------------------------------------\n",
    "\n",
    "first_img = test_input[0].reshape(28,28)\n",
    "second_img = test_input[1].reshape(28,28)\n",
    "print(\"first test image:\")\n",
    "plt.imshow(first_img, cmap='Greys')\n",
    "plt.show()\n",
    "print(\"second test image:\")\n",
    "plt.imshow(second_img, cmap='Greys')\n",
    "plt.show()\n",
    "\n",
    "print(\"interpolated images:\")\n",
    "num_images = 11\n",
    "plt.figure(figsize=(20,20))\n",
    "for i in range(num_images):\n",
    "  new_latent_representation = test_input_encoded[0] + i/10.0 * (test_input_encoded[1] - test_input_encoded[0])\n",
    "  new_img = decoder.predict(np.array([new_latent_representation]), batch_size=1)\n",
    "  new_img = new_img.reshape(28,28)\n",
    "  ax = plt.subplot(1, num_images, i+1)\n",
    "  plt.imshow(new_img, cmap='Greys')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "###------------------------------------------------------------------------------\n",
    "# Show encoded representations of test digits in latent space (two-dimensional!)\n",
    "###------------------------------------------------------------------------------\n",
    "\n",
    "# The latent representations are color-coded by their target labels (this is why we needed the targets)\n",
    "print(\"Latent representations of test images, color-coded by their true target labels\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(test_input_encoded[:, 0], test_input_encoded[:, 1], c=test_target, cmap='brg')\n",
    "plt.colorbar()\n",
    "# show also the representations of the two test images from above as a line in latent space\n",
    "# the end points of the lines are the latent representations of the first and second test images\n",
    "line = np.linspace(test_input_encoded[0], test_input_encoded[1], 100)\n",
    "plt.plot(line[:,0], line[:,1], color='black', linestyle='solid')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "###----------------------------------------------------------------------\n",
    "# Display a manifold of digits sampled from two-dimensional space\n",
    "###----------------------------------------------------------------------\n",
    "\n",
    "from scipy.stats import norm \n",
    "\n",
    "n = 20  # figure with 20x20 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "\n",
    "# Construct grid of latent variable values\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n)) # ppf: percent point function to calculate the inverse of the\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n)) #      ... continuous density function of the standard normal distribution\n",
    "\n",
    "# decode for each square in the grid\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        z_sample = np.tile(z_sample, batch_size).reshape(batch_size, 2)\n",
    "        x_decoded = decoder.predict(z_sample, batch_size=batch_size)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "print(\"Display a manifold of digits sampled from two-dimensional space\")\t\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys') # or cmap='gnuplot2'\n",
    "plt.show()  \n",
    "\n",
    "\n",
    "###----------------------------------------------------------------------\n",
    "# Generate any digit from a  random two-dimensional latent representation\n",
    "###----------------------------------------------------------------------\n",
    "\n",
    "latent_representation = np.array([-1.1, 0.8]) # FIX!!!\n",
    "# generate image from latent_representation\n",
    "new_img = decoder.predict(np.array([latent_representation]), batch_size=1)\n",
    "new_img = new_img.reshape(28,28)\n",
    "plt.imshow(new_img, cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gM0GeasL_Xu7"
   },
   "source": [
    "### Answer\n",
    "\n",
    "Write your answer here."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Sheet6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
