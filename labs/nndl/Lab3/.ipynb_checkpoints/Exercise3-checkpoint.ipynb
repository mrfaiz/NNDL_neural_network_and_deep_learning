{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MOitTdg3yP-M"
   },
   "source": [
    "# Important Information\n",
    "\n",
    "This file has two usages. \n",
    "1. This file can be displayed in Jupyter. You can read the task and insert your answers here. Start the notebook from an Anaconda prompt and change to the working directory containing the *.ipynb file.\n",
    "2. You can execute the code in Google Colab making use of Keras and Tensorflow. If you do not want to create a Google Account, you have to create a local environment for Keras and Tensorflow.\n",
    "\n",
    "For submission, upload your edited notebook together with all used images in a seperate folder (/images)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-CXSNwExJb1C"
   },
   "source": [
    "Setup for this exercise sheet. Download data and define Tensorflow version.\n",
    "Execute code only if you setup your enviroment correctly or if you are inside a colab enviroment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "Q7aTStJHJaay",
    "outputId": "7cd84744-a02f-4db8-ade2-21c81f6c4039"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'nndl'...\n",
      "remote: Enumerating objects: 32, done.\u001b[K\n",
      "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
      "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
      "remote: Total 32 (delta 8), reused 0 (delta 0), pack-reused 0\n",
      "Unpacking objects: 100% (32/32), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://gitlab+deploy-token-26:XBza882znMmexaQSpjad@git.informatik.uni-kiel.de/las/nndl.git\n",
    "\n",
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 (Learning in neural networks)\n",
    "\n",
    "a) Explain the following terms related to neural networks as short and precise as possible. \n",
    "\n",
    "* Learning in neural networks\n",
    "* Training set\n",
    "* Supervised Learning\n",
    "* Unsupervised Learning\n",
    "* Online (incremental) learning\n",
    "* Offline (batch) learning\n",
    "* Training error\n",
    "* Generalisation error\n",
    "* Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Answer: Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d8ahoTHxBW82"
   },
   "source": [
    "b) Name and briefly describe at least two methods to avoid overfitting when training neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Answer: Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dHDU9m2hChSn"
   },
   "source": [
    "# Exercise 2 (Perceptron learning – analytical calculation)\n",
    "\n",
    "The goal of this exercise is to train a single-layer perceptron (threshold element) to classify\n",
    "whether a fruit presented to the perceptron is going to be liked by a certain person or not,\n",
    "based on three features attributed to the presented fruit: its taste (whether it is sweet or not),\n",
    "its seeds (whether they are edible or not) and its skin (whether it is edible or not). This\n",
    "generates the following table for the inputs and the target output of the perceptron:\n",
    "\n",
    "Fruit | Input Taste<br>sweet = 1<br>not sweet = 0 | Input Seeds<br>edible = 1<br>not edible = 0 | Input Skin<br>edible = 1<br>not edible = 0 | Target output<br>person likes = 1<br>doesn’t like = 0\n",
    ":---|:---:|:---:|:---:|:---:\n",
    "Banana|1|1|0|1\n",
    "Pear|1|0|1|1\n",
    "Lemon|0|0|0|0\n",
    "Strawberry|1|1|1|1\n",
    "Green Apple|0|0|1|0\n",
    "\n",
    "Since there are three (binary) input values (taste, seeds and skin) and one (binary) target\n",
    "output, we will construct a single-layer perceptron with three inputs and one output.\n",
    "\n",
    "![IMAGE: perceptron](images/perceptron.png)\n",
    "\n",
    "Since the target output is binary, we will use the perceptron learning algorithm to construct the weights.\n",
    "\n",
    "To start the perceptron learning algorithm, we have to initialize the weights and the threshold.\n",
    "Since we have no prior knowledge on the solution, we will assume that all weights are 0 ($w_1 = w_2 = w_3 = 0$) and that the threshold is $\\theta = 1$ (i.e. $w_0 = -\\theta = -1$).\n",
    "Furthermore, we have to specify the learning rate $\\eta$.\n",
    "Since we want it to be large enough that learning happens in a reasonable amount of time, but small enough so that it doesn’t go too fast, we set $\\eta = 0.25$.\n",
    "\n",
    "Apply the perceptron learning algorithm – in the incremental mode – analytically to this problem, i.e. calculate the new weights and threshold after successively presenting a banana, pear, lemon, strawberry and a green apple to the network (in this order).\n",
    "\n",
    "Draw a diagram of the final perceptron indicating the weight and threshold parameters and verify that the final perceptron classifies all training examples correctly.\n",
    "\n",
    "Note: The iteration of the perceptron learning algorithm is easily accomplished by filling in the following table for each iteration of the learning algorithm:\n",
    "\n",
    "First iteration ($\\mu = 1$), current training sample: banana\n",
    "\n",
    "Input<br> ${x}^{(\\mu)}$ | Current Weights<br>$w(t)$ | Network Output<br>$y^{(\\mu)}$ | Target Ouput<br>$d^{(\\mu)}$ | Learning rate<br>$\\eta$ | Weight Update<br>$\\Delta w(t)$ | New weights<br>$w(t+1)$\n",
    ":---:|:---:|:---:|:---:|:---:|:---:|:---:\n",
    "$x_0$ = 1 |  $w_0$ = | | | 0.25 | | \n",
    "$x_1$ =  |  $w_1$ = | | | 0.25 | | \n",
    "$x_2$ =  |  $w_2$ = | | | 0.25 | | \n",
    "$x_3$ =  |  $w_3$ = | | | 0.25 | | \n",
    "\n",
    "Second iteration ($\\mu = 2$), current training sample: pear\n",
    "...\n",
    "\n",
    "\n",
    "(Source of exercise: Langston, Cognitive Psychology)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Answer: Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V0dZkCh_Cm2n"
   },
   "source": [
    "# Exercise 3 (Single-layer perceptron, gradient learning, 2dim. classification)\n",
    "\n",
    "The goal of this exercise is to solve a two-dimensional binary classification problem with gradient learning, using tensorflow.\n",
    "Since the problem is two-dimensional, the perceptron has 2 inputs. Since the classification problem is binary, there is one output.\n",
    "\n",
    "The (two-dimensional) inputs for training are provided in the file *exercise3b_input.txt*, the corresponding (1-dimensional) targets in the file *exercise3b_target.txt*. To visualize the results, the training samples corresponding to class 1 (output label “0”) have separately been saved in the file *exercise3b_class1.txt*, the training samples corresponding to class 2 (output label “1”) in the file *exercise3b_class2.txt*.\n",
    "\n",
    "The gradient learning algorithm – using the sigmoid activation function – shall be used to provide a solution to this classification problem. Note that due to the sigmoid activation function, the output of the perceptron is a real value in [0,1]:\n",
    "\n",
    "\\begin{equation}\n",
    "sigmoid(h) = \\frac{1}{1+e^{-h}}\n",
    "\\end{equation}\n",
    "To assign a binary class label (either 0 or 1) to an input example, the perceptron output $y$ can\n",
    "be passed through the Heaviside function $\\theta [ y - 0.5 ] $ to yield a binary output $y^{binary}$.\n",
    "Then, any perceptron output between 0.5 and 1 is closer to 1 than to 0 and will be assigned the class label “1”.\n",
    "Conversely, any perceptron output between 0 and $<0.5$ is closer to 0 than to 1 and will be assigned the class label “0”.\n",
    "As usual, denote the weights of the perceptron $w_1$ and $w_2$ and the bias $w_0 = -\\theta $.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QUX94DzGW0Jh"
   },
   "source": [
    "## Task a)\n",
    "\n",
    "Using the above-mentioned post-processing step $\\theta [ y - 0.5 ] $  applied to the perceptron output $y$, show that the decision boundary separating the inputs $x=( x_1 , x_2 )$ assigned to class label “1” from those inputs assigned to class label “0” is given by a straight line in two-dimensional space corresponding to the equation (see below at *# plot last decision boundary*): \n",
    "\n",
    "$x_2 = -\\frac{w_1}{w_2}x_1 - \\frac{w_0}{w_2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Answer: Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1bOBn82oXXU7"
   },
   "source": [
    "## Task b)\n",
    "\n",
    "The classification problem (defined by the training data provided in *exercise3b_input.txt* and the targets provided in *exercise3b_target.txt*)\n",
    "shall now be solved using the tensorflow and keras libraries.\n",
    "The source code is given below and can be executed by clicking the play button (in colab or in a local installation with tensorflow and keras).\n",
    "\n",
    "1.   Train the model for at least three times and report on your findings.\n",
    "2.   Change appropriate parameters (e.g. the learning rate, the batch size, the choice of the solver, potentially the number of epochs etc.) and again report on your findings.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6tA_K3-BAyw",
    "outputId": "eff8b5af-1f29-46f9-b35b-ff6d276c63ca"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-29a04673b016>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "###-----------------\n",
    "# load training data\n",
    "###-----------------\n",
    "path_to_task = \"nndl/Exercise3\"\n",
    "input = np.loadtxt(join(path_to_task,'exercise3b_input.txt'))\n",
    "tmp = np.loadtxt(join(path_to_task,'exercise3b_target.txt'))\n",
    "target = np.array([tmp[i] for i in range(tmp.size)])\n",
    "class1 = np.loadtxt(join(path_to_task,'exercise3b_class1.txt'))\n",
    "class2 = np.loadtxt(join(path_to_task,'exercise3b_class2.txt'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iF1QcuBwBFdW"
   },
   "source": [
    "\n",
    "Define the neural network, here you can change the structure of network, the learning rate and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "HprUKTffLDnq"
   },
   "outputs": [],
   "source": [
    "# Define the structure\n",
    "input_layer = Input(shape=(2,), name='input') # two dimensional input\n",
    "out = Dense(units=1, activation=\"sigmoid\", name=\"output\")(input_layer) # one ouput node with sigmoid activation\n",
    "\n",
    "# create a model\n",
    "model = Model(input_layer, out)\n",
    "\n",
    "# show how the model looks\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "opt = SGD(learning_rate=0.01)\n",
    "model.compile(optimizer=opt,loss=\"binary_crossentropy\",metrics=[\"acc\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "idMWZMOMYMv5"
   },
   "source": [
    "This line actually trains the model. Changeable parameters batch_size and epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "q0YZ0ZFcOdI1"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(x=input, y=target, batch_size=1, epochs=100, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sNL1qLxHYVbO"
   },
   "source": [
    "The following code snippet plots the results you create in the snippet before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Dycq1s9UJ20r"
   },
   "outputs": [],
   "source": [
    "# plot setup\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 15))\n",
    "legend = []\n",
    "\n",
    "# plot the data\n",
    "axes[0].set_title('Toy classification problem: Data and decision boundaries')\n",
    "axes[0].set_xlabel('x1')\n",
    "axes[0].set_ylabel('x2')\n",
    "minx = min(input[:,0])\n",
    "maxx = max(input[:,0])\n",
    "miny = min(input[:,1])\n",
    "maxy = max(input[:,1])\n",
    "\n",
    "axes[0].set_xlim(minx, maxx)\n",
    "axes[0].set_ylim(miny, maxy) \n",
    "axes[0].plot(class1[:,0], class1[:,1], 'r.', \\\n",
    "    class2[:,0], class2[:,1], 'b.')\n",
    "legend.append('samples class1')\n",
    "legend.append('samples class2')\n",
    "\n",
    "# calculate decision boundary\n",
    "weights = model.layers[-1].get_weights()\n",
    "w0 = weights[1][0] # bias\n",
    "\n",
    "# weights (list of of numpy arrays of shape n_in x n_out)\n",
    "w1 = weights[0][0][0]\n",
    "w2 = weights[0][1][0]\n",
    "if ( w2 == 0 ):\n",
    "    print(\"Error: second weight zero!\")\n",
    "\n",
    "# plot last decision boundary\n",
    "interval = np.arange( np.floor(minx), np.ceil(maxx), 0.1 )\n",
    "line = -w1*interval/w2 - w0/w2\n",
    "args = {'c': 'black', 'linestyle': '-'}\n",
    "axes[0].plot( interval, line, **args)\n",
    "\n",
    "# plot loss curve \n",
    "axes[1].plot(history.history['loss'])\n",
    "axes[1].set_title('Toy classification problem: Loss curve')\n",
    "axes[1].set_xlabel('Epoch number')\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[1].set_ylabel('loss')\n",
    "\n",
    "# plot loss curve \n",
    "axes[2].plot(history.history['acc'])\n",
    "axes[2].set_title('Toy classification problem: acc curve')\n",
    "axes[2].set_ylim(0, 1)\n",
    "axes[2].set_xlabel('Epoch number')\n",
    "axes[2].set_ylabel('acc')\n",
    "\n",
    "# show the plot\n",
    "fig.legend(axes[0].get_lines(), legend, ncol=3, loc=\"upper center\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v19EGJbpYf3k"
   },
   "source": [
    "## Answer\n",
    "TODO report your findings here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bCk4EokGYqSi"
   },
   "source": [
    "**TODO - Further assigments missing**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
